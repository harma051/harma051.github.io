<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Dispossessed Capable - Chris Harman</title>

    <meta property="og:title" content="The Dispossessed Capable - Chris Harman">
    <meta property="og:description" content="A response to Dario Amodei's essay arguing that human observability of AI work could simultaneously address alignment and labor displacement.">
    <meta property="og:image" content="https://harma051.github.io/profile.jpg">
    <meta property="og:url" content="https://harma051.github.io/posts/ai-risks-response.html">
    <meta property="og:type" content="article">

    <meta name="description" content="A response to Dario Amodei's essay arguing that human observability of AI work could simultaneously address alignment and labor displacement.">

    <link rel="stylesheet" href="../styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        .blog-header {
            text-align: center;
            padding: 60px 40px 20px;
            margin-top: 20px;
        }

        .blog-header h1 {
            margin: 0;
            font-size: 2rem;
            font-weight: 600;
            line-height: 1.3;
            letter-spacing: -0.02em;
            color: var(--text-color);
        }

        .blog-header .author {
            color: var(--text-color);
            margin-top: 16px;
            font-size: 1rem;
        }

        .blog-header .date {
            color: var(--text-muted);
            margin-top: 8px;
            font-size: 0.95rem;
        }

        .blog-content {
            color: var(--text-body);
            font-size: 1rem;
            line-height: 1.7;
            max-width: 650px;
            margin: 0 auto;
            padding: 0 20px;
            text-align: justify;
        }

        .blog-content p {
            margin: 1.5em 0;
        }

        .blog-content h2 {
            margin: 2.5em 0 1em 0;
            font-size: 1.25rem;
            font-weight: 600;
            text-align: center;
            color: var(--text-color);
        }

        .blog-content ul, .blog-content ol {
            padding-left: 1.5em;
            margin: 1.25em 0;
        }

        .blog-content li {
            margin: 0.5em 0;
        }

        .blog-content blockquote {
            border-left: 2px solid var(--border-color);
            margin: 1.5em 0;
            padding: 1em 1.5em;
            font-style: italic;
            background: rgba(128, 128, 128, 0.06);
        }

        .blog-content blockquote cite {
            display: block;
            margin-top: 0.5em;
            font-size: 0.9em;
            font-style: normal;
            opacity: 0.8;
        }

        .intro {
            /* Same as body text for uniform readability */
        }

        .sa-taxonomy {
            border: 1px solid var(--border-color);
            padding: 1.5em;
            margin: 1.5em 0;
            background: rgba(128, 128, 128, 0.06);
            text-align: center;
        }

        .sa-taxonomy h4 {
            margin: 0 0 0.75em 0;
            font-size: 1em;
            font-weight: 600;
            text-align: left;
        }

        .sa-taxonomy ul {
            margin: 0;
            padding-left: 1.5em;
            text-align: left;
            list-style-type: none;
        }

        .sa-taxonomy li::before {
            content: "– ";
        }

        .sa-taxonomy li {
            margin: 0.35em 0;
            font-size: 0.95em;
            white-space: nowrap;
        }

        .sa-level {
            margin-bottom: 1.25em;
        }

        .sa-level:last-child {
            margin-bottom: 0;
        }

        .references {
            margin-top: 3em;
            padding-top: 1.5em;
            border-top: 1px solid var(--border-color);
        }

        .references h3 {
            font-size: 1.1em;
            font-weight: 600;
            margin-bottom: 1em;
        }

        .references ol {
            padding-left: 1.5em;
            margin: 0;
        }

        .references li {
            margin: 0.75em 0;
            font-size: 0.9em;
            line-height: 1.6;
        }

        .references a {
            word-break: break-word;
        }

        sup {
            color: var(--link-color);
            font-weight: 500;
        }

        sup a {
            color: var(--link-color);
            text-decoration: none;
        }

        sup a:hover {
            text-decoration: underline;
        }

        .toc {
            position: fixed;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            background: var(--bg-color);
            border: 1px solid var(--border-color);
            padding: 16px 20px;
            z-index: 100;
            max-width: 200px;
            opacity: 0;
            transition: opacity 0.2s ease, background 0.2s ease, border-color 0.2s ease;
        }

        .toc.visible {
            opacity: 1;
        }

        .toc h4 {
            color: var(--text-body);
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin: 0 0 12px 0;
        }

        .toc ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .toc li {
            margin: 8px 0;
        }

        .toc a {
            color: var(--text-body);
            font-size: 0.85rem;
            text-decoration: none;
            display: block;
            padding: 4px 0;
            border-left: 2px solid transparent;
            padding-left: 12px;
            margin-left: -12px;
            opacity: 0.7;
        }

        .toc a:hover {
            opacity: 1;
        }

        .toc a.active {
            color: var(--link-color);
            border-left-color: var(--link-color);
            opacity: 1;
        }

        @media (max-width: 1400px) {
            .toc {
                display: none;
            }
        }

        @media (max-width: 600px) {
            .blog-header h1 {
                font-size: 1.6rem;
            }

            .sa-taxonomy {
                padding: 16px;
            }
        }
    </style>
</head>
<body>

<button class="theme-toggle" onclick="toggleTheme()">Light</button>

<nav class="toc" id="toc">
    <h4>Contents</h4>
    <ul>
        <li><a href="#dispossessed">When Capability Becomes Liability</a></li>
        <li><a href="#sf-bubble">The SF Bubble</a></li>
        <li><a href="#control">The Question of Control</a></li>
        <li><a href="#resilience">Building Resilience</a></li>
    </ul>
</nav>

<section class="blog-header">
    <h1>The Dispossessed Capable</h1>
    <p class="author">Chris Harman</p>
    <p class="date">January 27, 2026</p>
</section>

<section class="blog-content">
    <p class="intro">Dario just released his <a href="https://darioamodei.com/essay/the-adolescence-of-technology">new essay</a> on the risks of AI. His thinking and writing are clear, compelling, and balanced. Since I broadly agree with his points and could not articulate them more clearly than he has, I will instead cover some important gaps and offer some perspective on how labs could <strong><em>simultaneously limit labor disruption while improving alignment</em></strong>. My points build on each other and culminate in some solutions that feel like a hopeful path forward.</p>

    <h2 id="dispossessed">1. When Capability Becomes Liability</h2>

    <p>Dario discusses the makeup of individuals who can cause large-scale destruction as those who have both capability and motive, pointing out that these traits are typically negatively correlated:</p>

    <blockquote>
        "The kind of person who has the ability to release a plague is probably highly educated: likely a PhD in molecular biology, and a particularly resourceful one, with a promising career, a stable and disciplined personality, and a lot to lose."
    </blockquote>

    <p>He is concerned that the widespread distribution of AI:</p>

    <blockquote>
        "...will break the correlation between ability and motive: the disturbed loner who wants to kill people but lacks the discipline or skill to do so will now be elevated to the capability level of the PhD virologist, who is unlikely to have this motivation."
    </blockquote>

    <p>However, the other side of the coin may present more risk, namely <strong><em>the risk from currently high-capability people who become dispossessed by the AI era</em></strong>. There will be tremendous numbers of people who have worked for years or decades on the skills they use to support themselves. They will have to watch AI surpass their abilities and perhaps take their employment.</p>

    <p>What will happen to those people? Is there a place for those people in this new society?</p>

    <p>This question leads directly to the next issue&mdash;the risk that negative public perception of AI becomes so strong that we effectively cede the race to China.</p>

    <h2 id="sf-bubble">2. The SF Bubble</h2>

    <p><strong><em>Agents don't vote. People do.</em></strong></p>

    <p>I've heard it said that "SF" is a state of mind. I like this idea, as it's frequently the state my mind occupies. However, I also live outside of physical SF and interact mostly with people who think poorly of SF&mdash;if they think of it at all. The SF bubble massively overestimates how sold the public is on the idea that the benefits of AI outweigh the costs.</p>

    <p>This has not yet become a meaningful problem because the issue has not been forced. This will obviously change.</p>

    <p>Many current benefits (code generation, streamlined research, automation) are diffuse, most directly realized in the hands of those who use AI, while many downsides (job loss, sophisticated targeted scams, bot takeover of social media) can be felt directly—particularly by those who do not use AI. Given these different experiences, what should people think about when they think about AI?</p>

    <p>Will targets of AI-driven layoffs care that the geniuses might cure cancer eventually? Will fresh graduates appreciate the potential abundance of affordable food if they can't participate in the game?</p>

    <p>AI is clearly not yet ready to solve all the world's problems. But it may need to start producing clearly positive externalities that the public can see and appreciate.</p>

    <p>This is challenging because solved problems tend to disappear from people's views and expectations, but I could see a two-pronged approach:</p>

    <ol>
        <li><strong><em>Here's the fallback to keep you going if AI takes your job.</em></strong> Here's how we have dropped the costs of the essentials needed to live. Here's how you can pay for a place to live, eat good food, and take care of your children.</li>
        <li><strong><em>Here is the moonshot.</em></strong> Here is how AI is solving a visible, pernicious problem in a highly agreeable way. It should be ambitious&mdash;if you could do it without AI, there is little point&mdash;yet also tractable. Curing disease is great for getting broad public approval, but progress in that area is uneven, and gains are opaque to the average person.</li>
    </ol>

    <p>Whether this approach is taken or not, it seems essential that the visible good from AI outweighs the bad clearly during this transitional period, or there is real risk that it will become highly popular for the government to meaningfully hamper AI progress.</p>

    <h2 id="control">3. The Question of Control</h2>

    <p>In <em>"The odious apparatus"</em> Dario calls out the potential for authoritative control from various parties: the CCP, competitive democracies, non-democratic countries, AI companies.</p>

    <p>This is a significant concern, but as Dario is well aware there is another: <strong><em>If datacenters can manufacture consent and create unbeatable drones, they are the new superpower.</em></strong></p>

    <p>Part of why economists and political scientists often seem to disagree is that economics is a non-zero-sum game, but political power is a zero-sum game. The United States or any other governing authority is likely to be excited about the economic potential of AI while it plays the game of economics. But that game will eventually become political. Will the United States government allow an internal power that is greater than its own?</p>

    <p>At the risk of sounding like an LLM&mdash;it's not that this level of power could fall into the wrong hands. It's that this power MUST be driven by someone or something. Who will that be?</p>

    <ul>
        <li>Government officials?</li>
        <li>Private companies?</li>
        <li>Individuals?</li>
        <li>A national population?</li>
        <li>Will the systems govern themselves?</li>
    </ul>

    <p>It is not difficult to imagine the likely downfalls of each of those options.</p>

    <p>It seems unlikely that the infinite abundance of post-scarcity will change human nature itself and eliminate the desire for power or need for status games. How do those games play out if there is a centralized power that trivializes all other powers?</p>

    <p>It is insufficient to care about the wrong group gaining access to the technology; the challenge is that whatever group controls it could end up being "the wrong group."</p>

    <p>What if the problems described here are actually pieces of the solution?</p>

    <h2 id="resilience">4. Building Resilience</h2>

    <p>Everyone knows that prediction is very difficult&mdash;"especially if it's about the future," as Niels Bohr reportedly quipped.<sup><a href="#ref-1">[1]</a></sup> Significantly, there is also the Nassim Taleb spin:</p>

    <blockquote>
        "The inability to predict outliers implies the inability to predict the course of history."<sup><a href="#ref-2">[2]</a></sup>
        <br><br>
        "What is nonmeasurable and nonpredictable will remain nonmeasurable and nonpredictable ... no matter how much hate mail I get."<sup><a href="#ref-3">[3]</a></sup>
        <cite>&mdash; Nassim Nicholas Taleb</cite>
    </blockquote>

    <p>Notably, Taleb points out that the best responses to inherent unpredictability are not to develop better forecasting, but to focus on building resilience (or even antifragility).</p>

    <p><strong><em>One path towards resilience is building tooling to support the observability and alignment of the work produced by the datacenter geniuses.</em></strong> Monitoring the alignment of the models themselves is the obvious step Anthropic works hard at, but the tools for interacting with these models also need to present information about the work that is done in a clear way.</p>

    <p>A slightly misaligned Claude could conceivably write a backdoor into every software system it has access to, and the current observability tooling is likely insufficient for the human in the loop to catch it. Certainly there will be systems of models watching models, and tracking the work production of a million geniuses seems daunting. Yet AI watching AI, while a useful approach, is a highly jagged interaction to stake humanity on. <strong><em>Human observability of the work AI produces is an essential frontier.</em></strong></p>

    <p>Dario notes that humans may be unable to offer work of meaningful value to the AIs. <strong><em>My alternative view is that human observation of the alignment of AI work output is of effectively unlimited economic value; proper observation of the alignment of AI's work could mean that we realize an infinitely growing economy, while failure to do so could have existential consequences.</em></strong></p>

    <p>As one example, Claude Code is a tremendous tool for producing code, but it is challenging to track its work from within the tool itself. Code scrolls by at rates faster than a human can comprehend, and it is often presented context-free. The natural desire to run multiple instances means that users are likely not even viewing the stream. Clearly there are some mechanisms for addressing these issues, but they are learned operational behaviors rather than exposed parts of the tooling itself.</p>

    <p>Interestingly, this is a design space with a long history. During the 1960s, significant debates took place in NASA around the appropriate level of flight automation. Too many systems with a manual structure might mean the astronauts would become overwhelmed during critical phases. Too much automation might mean the astronauts would become disengaged and fail to intervene when necessary.</p>

    <p>Some thoughts on this dynamic come from the study of Situation Awareness. Endsley (1995) provides a taxonomy of errors:<sup><a href="#ref-4">[4]</a></sup></p>

    <div class="sa-taxonomy">
        <div class="sa-level">
            <h4>Level 1: Failure to Correctly Perceive the Situation</h4>
            <ul>
                <li>Data not available</li>
                <li>Hard to discriminate or detect data</li>
                <li>Failure to monitor or observe data</li>
                <li>Misperception of data</li>
                <li>Memory loss</li>
            </ul>
        </div>

        <div class="sa-level">
            <h4>Level 2: Improper Integration or Comprehension of the Situation</h4>
            <ul>
                <li>Lack of or poor mental model</li>
                <li>Use of incorrect mental model</li>
                <li>Overreliance on default values</li>
            </ul>
        </div>

        <div class="sa-level">
            <h4>Level 3: Incorrect Projection of Future Actions of the System</h4>
            <ul>
                <li>Lack of or poor mental model</li>
                <li>Overprojection of current trends</li>
            </ul>
        </div>
    </div>

    <p>There are reasonable arguments to be made that the design of Claude Code makes it easy for users to fall prey to errors at each of those levels. There is a large divide between making systems designed for humans, systems designed for machines, and systems designed for human-machine cooperation.</p>

    <p>Claude's constitutional principles offer a way for Claude to enter any situation with core principles that are likely to provide good results. However, those principles will be tested against the complexities of reality at increasing scale. Feedback from broad groups of highly skilled humans can provide the data needed to continue to refine the core principles and potential special exceptions.</p>

    <p>While not every automated AI action across the economy needs constant monitoring, we will want to be able to actually check any section of the economy with ergonomics appropriate for the task. The sooner we can build and start getting feedback on these observational systems that keep humans engaged productively in the loop, the better those systems will be when they are needed most.</p>

    <p>The dispossessed capable would be offered meaningful work. An advanced biology degree would still be valuable—really, more valuable than ever given the level of work it could allow the datacenter geniuses to produce.</p>

    <p>Despite the challenges listed here, I remain hopeful that we can produce an AI future that steers towards flourishing for all.</p>

    <div class="references">
        <h3>References</h3>
        <ol>
            <li id="ref-1">This quote is often attributed to Niels Bohr, though its origin is uncertain. Various forms appear in Danish folklore and have been attributed to multiple figures including Yogi Berra and Mark Twain. See: Quote Investigator, "<a href="https://quoteinvestigator.com/2013/10/20/no-predict/">It's Difficult to Make Predictions, Especially About the Future</a>."</li>
            <li id="ref-2">Taleb, N. N. (2007). <em>The black swan: The impact of the highly improbable</em>. Random House.</li>
            <li id="ref-3">Taleb, N. N. (2012). <em>Antifragile: Things that gain from disorder</em> (p. 138). Random House.</li>
            <li id="ref-4">Endsley, M. R. (1995). A taxonomy of situation awareness errors. In R. Fuller, N. Johnston, & N. McDonald (Eds.), <em>Human factors in aviation operations: Proceedings of the 21st conference of the European Association for Aviation Psychology (EAAP)</em>, Vol. 3 (pp. 287-292). Avebury Aviation.</li>
        </ol>
    </div>
</section>

<section class="nav">
    <p><a href="../blog.html">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5L3 12m0 0l7.5-7.5M3 12h18" />
        </svg>
        Back to Blog
    </a></p>
    <p><a href="../index.html">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" d="M2.25 12l8.954-8.955c.44-.439 1.152-.439 1.591 0L21.75 12M4.5 9.75v10.125c0 .621.504 1.125 1.125 1.125H9.75v-4.875c0-.621.504-1.125 1.125-1.125h2.25c.621 0 1.125.504 1.125 1.125V21h4.125c.621 0 1.125-.504 1.125-1.125V9.75M8.25 21h8.25" />
        </svg>
        Home
    </a></p>
    <p><a href="https://www.linkedin.com/in/christopher-harman-02180a57">
        <svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24">
            <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
        </svg>
        LinkedIn
    </a></p>
    <p><a href="../chris_harman_resume.pdf">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 00-3.375-3.375h-1.5A1.125 1.125 0 0113.5 7.125v-1.5a3.375 3.375 0 00-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 00-9-9z" />
        </svg>
        Resume
    </a></p>
    <p><a href="mailto:chrisharman051@gmail.com?subject=Hello!">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" d="M21.75 6.75v10.5a2.25 2.25 0 01-2.25 2.25h-15a2.25 2.25 0 01-2.25-2.25V6.75m19.5 0A2.25 2.25 0 0019.5 4.5h-15a2.25 2.25 0 00-2.25 2.25m19.5 0v.243a2.25 2.25 0 01-1.07 1.916l-7.5 4.615a2.25 2.25 0 01-2.36 0L3.32 8.91a2.25 2.25 0 01-1.07-1.916V6.75" />
        </svg>
        Contact
    </a></p>
</section>

<script>
function toggleTheme() {
    const html = document.documentElement;
    const btn = document.querySelector('.theme-toggle');
    if (html.getAttribute('data-theme') === 'light') {
        html.removeAttribute('data-theme');
        btn.textContent = 'Light';
        localStorage.setItem('theme', 'dark');
    } else {
        html.setAttribute('data-theme', 'light');
        btn.textContent = 'Dark';
        localStorage.setItem('theme', 'light');
    }
}

(function() {
    const saved = localStorage.getItem('theme');
    const btn = document.querySelector('.theme-toggle');
    if (saved === 'light') {
        document.documentElement.setAttribute('data-theme', 'light');
        btn.textContent = 'Dark';
    }
})();

const toc = document.getElementById('toc');
const sections = document.querySelectorAll('h2[id]');
const tocLinks = document.querySelectorAll('.toc a');

function updateTocVisibility() {
    const scrollY = window.scrollY;
    if (scrollY > 200) {
        toc.classList.add('visible');
    } else {
        toc.classList.remove('visible');
    }
}

function updateActiveSection() {
    let current = '';
    const offset = 150;

    sections.forEach(section => {
        const sectionTop = section.offsetTop;
        if (window.scrollY >= sectionTop - offset) {
            current = section.getAttribute('id');
        }
    });

    tocLinks.forEach(link => {
        link.classList.remove('active');
        if (link.getAttribute('href') === '#' + current) {
            link.classList.add('active');
        }
    });
}

tocLinks.forEach(link => {
    link.addEventListener('click', (e) => {
        e.preventDefault();
        const targetId = link.getAttribute('href').slice(1);
        const target = document.getElementById(targetId);
        if (target) {
            target.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
    });
});

window.addEventListener('scroll', () => {
    updateTocVisibility();
    updateActiveSection();
});

updateTocVisibility();
updateActiveSection();
</script>

<script data-goatcounter="https://chrisharman.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>

</body>
</html>
